{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef56a07-3afd-460a-8205-36fb5dfb8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q\n",
    "#  pip install evaluate\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('punkt_tab')\n",
    "# Dataset : CNN_Dailymail\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"cnn_dailymail\", '3.0.0')\n",
    "\n",
    "print(f\"Features in cnn daily_mail : {dataset['train'].column_names}\")\n",
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"\n",
    "Article (excerpt of 500 charachters, total length: {len(sample[\"article\"])}):\n",
    "\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f'\\nSummary (length: {len(sample[\"highlights\"])}):')\n",
    "print(sample[\"highlights\"])\n",
    "## Text Summarization Pipelines\n",
    "sample_text = dataset['train'][1]['article'][:1000]\n",
    "\n",
    "#We'll collect the generated summaries of each model in a dictionary\n",
    "summaries = {}\n",
    "### Summarization Baseline\n",
    "def baseline_summary_three_sent(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "summaries['baseline'] = baseline_summary_three_sent(sample_text)\n",
    "\n",
    "summaries['baseline']\n",
    "### gpt2 model\n",
    "from transformers import pipeline, set_seed\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Initialize the text-generation pipeline using GPT-2 medium\n",
    "pipe = pipeline('text-generation', model='gpt2-medium')\n",
    "\n",
    "# Input query\n",
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "\n",
    "# Generate text (removing 'clean_up_tokenization_space')\n",
    "pipe_out = pipe(gpt2_query, max_length=512)\n",
    "\n",
    "\n",
    "pipe_out\n",
    "pipe_out[0]['generated_text'][len(gpt2_query) :]\n",
    "summaries['gpt2'] = \"\\n\".join(sent_tokenize(pipe_out[0]['generated_text'][len(gpt2_query) :]))\n",
    "### T5\n",
    "pipe = pipeline('summarization', model='t5-small')\n",
    "\n",
    "pipe_out = pipe(sample_text)\n",
    "pipe_out\n",
    "summaries['t5'] = \"\\n\".join(sent_tokenize(pipe_out[0]['summary_text']))\n",
    "### BART\n",
    "pipe = pipeline('summarization', model='facebook/bart-large-cnn')\n",
    "\n",
    "pipe_out = pipe(sample_text)\n",
    "pipe_out\n",
    "summaries['bart'] = \"\\n\".join(sent_tokenize(pipe_out[0]['summary_text']))\n",
    "### PEGASUS\n",
    "pipe = pipeline('summarization', model=\"google/pegasus-cnn_dailymail\")\n",
    "\n",
    "pipe_out = pipe(sample_text)\n",
    "pipe_out\n",
    "summaries['pegasus'] = pipe_out[0]['summary_text'].replace (\" .<n>\", \".\\n\")\n",
    "## Comparing different Summaries\n",
    "print(\"GROUND TRUTH\")\n",
    "\n",
    "print(dataset['train'][1]['highlights'])\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "\n",
    "# SacreBLEU\n",
    "# pip install sacrebleu\n",
    "import evaluate\n",
    "\n",
    "bleu_metric = evaluate.load('sacrebleu')\n",
    "import numpy as np\n",
    "# Load the BLEU metric\n",
    "bleu_metric = evaluate.load('sacrebleu')\n",
    "\n",
    "# Define the predictions and references\n",
    "predictions = [summaries[\"pegasus\"]]\n",
    "references = [[dataset['train'][1]['highlights']]]  # Note: References should be a list of lists\n",
    "\n",
    "# Compute the BLEU score\n",
    "results = bleu_metric.compute(predictions=predictions, references=references, smooth_method='floor', smooth_value=0)\n",
    "\n",
    "# Format precision values\n",
    "results['precision'] = [np.round(p, 2) for p in results['precisions']]\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "bleu_results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Value'])\n",
    "bleu_results_df\n",
    "# ROUGE\n",
    "# pip install rouge_score\n",
    "rouge_metric = evaluate.load('rouge')\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "# Load the ROUGE metric\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "# List of ROUGE metrics to extract\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "# Reference summary\n",
    "reference = dataset['train'][1]['highlights']\n",
    "\n",
    "# Store results\n",
    "records = []\n",
    "\n",
    "# Compute ROUGE scores for all model summaries\n",
    "for model_name in summaries:\n",
    "    # Add predictions and references\n",
    "    score = rouge_metric.compute(\n",
    "        predictions=[summaries[model_name]], references=[reference]\n",
    "    )\n",
    "\n",
    "    # Extract ROUGE scores\n",
    "    rouge_dict = {}\n",
    "    for rn in rouge_names:\n",
    "        if rn in score:\n",
    "            rouge_dict[rn] = score[rn]  # Directly assign the scalar value\n",
    "\n",
    "    print(\"ROUGE scores for model:\", model_name, rouge_dict)\n",
    "\n",
    "    # Add scores to records\n",
    "    records.append({\"model\": model_name, **rouge_dict})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Set the model name as index\n",
    "df.set_index(\"model\", inplace=True)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "### Evaluating on the TEST set of the CNN/DailyMail dataset\n",
    "def calculate_metric_on_baseline_test_ds(dataset, metric, column_text='article',column_summary = 'highlights'):\n",
    "  summaries = [baseline_summary_three_sent(text) for text in dataset[column_text]]\n",
    "  metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
    "  score = metric.compute()\n",
    "  return score\n",
    "test_sampled = dataset['train'].shuffle(seed = 42).select(range(1000))\n",
    "\n",
    "score=calculate_metric_on_baseline_test_ds(test_sampled, rouge_metric)\n",
    "rouge_dict = {}\n",
    "\n",
    "for rn in rouge_names:\n",
    "    if rn in score:\n",
    "        rouge_dict[rn] = score[rn]  #  # Directly assign the scalar value\n",
    "\n",
    "pd.DataFrame.from_dict(rouge_dict, orient='index', columns=['Value'])\n",
    "### Strategy to calculate the ROUGE Metric on test dataset for the other Models\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "def generate_batch_sized_chunks(list_of_elements, batch_size):\n",
    "    \"\"\"split the dataset into smaller batches that we can process simultaneously\n",
    "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def calculate_metric_on_test_ds(dataset, metric, model, tokenizer,\n",
    "                               batch_size, device=device,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    article_batches = list(generate_batch_sized_chunks(dataset[column_text],batch_size))\n",
    "    target_batches = list(generate_batch_sized_chunks(dataset[column_summary],batch_size))\n",
    "\n",
    "    for article_batch, target_batch in tqdm(zip(article_batches, target_batches), total=len(article_batches)):\n",
    "\n",
    "        inputs = tokenizer(article_batch, max_length = 1024, truncation = True, padding = 'max_length',return_tensors = 'pt')\n",
    "\n",
    "        summaries = model.generate(input_ids = inputs['input_ids'].to(device), attention_mask = inputs['attention_mask'].to(device),\n",
    "                                    length_penalty = 0.8, num_beams = 8, max_length = 128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True) for s in summaries]\n",
    "\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "\n",
    "    score = metric.compute()\n",
    "    return score\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
    "\n",
    "score = calculate_metric_on_test_ds(test_sampled, rouge_metric, model_pegasus, tokenizer, batch_size=2)\n",
    "\n",
    "pd.DataFrame(rouge_dict, index = ['pegasus'] )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
